def create_model(X_train,y_train_cat,y_train,X_test,y_test_cat,y_test,max_sequence_len,total_words,epochs):
    input_len = max_sequence_len
    print(input_len)
    model = Sequential()
    model.add(Embedding(total_words,32 , input_length=input_len))
    model.add(Dropout(0.3))
    model.add(Conv1D(32,
                     5,
                     padding='same',
                     activation='tanh',
                     strides=1,kernel_regularizer=regularizers.l2(0.05)))
    model.add(MaxPooling1D(pool_size=5))
    model.add(Dropout(0.4))
    model.add(Conv1D(64,5,activation='tanh',kernel_regularizer=regularizers.l2(0.01)))
    model.add(MaxPooling1D(pool_size=5))
    model.add(Dropout(0.4))
    model.add(LSTM(32,activation='tanh'))
    model.add(Dropout(0.4))
    model.add(Dense(9,activation='softmax'))
    print(model.summary())
    model.compile(loss='categorical_crossentropy',  optimizer='adam',metrics=['accuracy'])
    model.fit(X_train,y_train_cat,epochs=epochs,verbose=1 ,validation_data=(X_test,y_test_cat), batch_size=20)
    loss, accuracy = model.evaluate(X_test, y_test_cat, verbose=False)
    
    plot_confusion_matrix(y_test, y_pr_class, classes=labels, normalize=True,
                          title='Normalized confusion matrix')
    plt.show()

    return loss,accuracy
